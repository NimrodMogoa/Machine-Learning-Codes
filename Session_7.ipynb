{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Session 7\n",
        "\n",
        "Review\n",
        "\n",
        "Files need\n",
        "* ACMETelephoneABT.csv\n",
        "* imdb_reviews.csv\n",
        "---\n",
        "\n",
        "\n",
        "Michael de la Maza\n",
        "\n",
        "AI/ML\n",
        "\n",
        "Hult International Business School\n",
        "\n",
        "Based on \"Fundamentals of Machine Learning for Predictive Data Analytics\" by Kelleher, et al"
      ],
      "metadata": {
        "id": "xlZkuroWsDno"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ACME Telephone Case Study\n",
        "\n",
        "\n",
        "\n",
        "*   Decision Tree\n",
        "*   Random Forest\n",
        "*   XGBoost\n",
        "*   MLPClassifier\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "7V07TA0GtvsP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Load data and check"
      ],
      "metadata": {
        "id": "L1jVS6oksV4G"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "DG_XPt8evDd8"
      },
      "outputs": [],
      "source": [
        "# Load dataset\n",
        "import pandas as pd\n",
        "df = pd.read_csv('ACMETelephoneABT.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check\n",
        "print(df.head())"
      ],
      "metadata": {
        "id": "t86j7PiUvrqu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Descriptive statistics\n",
        "descriptive_stats = df.describe(include='all')\n",
        "print(descriptive_stats)"
      ],
      "metadata": {
        "id": "K5I6OtnKvoKl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Exercise - 5 minutes\n",
        "# Examine the descriptive statistics. What do you see?"
      ],
      "metadata": {
        "id": "RqnxbH02wrak"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Histograms for numerical attributes\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "df.hist(figsize=(20, 16), bins=10, grid=True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "HQMxvGRgxhnP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Exercise - 5 minutes\n",
        "# What do you see in the histograms?\n",
        "# Look at 'lastMonthCustomerCareCalls'? What does this indicate?"
      ],
      "metadata": {
        "id": "SIJA5Li10aX-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show attribute names\n",
        "print(df.columns)\n",
        "print(df.dtypes)"
      ],
      "metadata": {
        "id": "MrUuIqdy2kT-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create stacked bar chart for regionType by churn\n",
        "grouped = df.groupby([' regionType', 'churn']).size().groupby(level=0).apply(lambda x: 100 * x / x.sum()).unstack('churn')\n",
        "\n",
        "grouped.plot(kind='bar', stacked=True, figsize=(10, 6))\n",
        "\n",
        "plt.title('Stacked Bar Chart of Region Type by Churn')\n",
        "plt.xlabel('Region Type')\n",
        "plt.ylabel('Count')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "nhL44zVL2H_l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Exercise - 5 minutes\n",
        "# Select another attribute of interest\n",
        "# Create a stacked bar chart. Analyze."
      ],
      "metadata": {
        "id": "WnVcmeym3jNb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create stacked bar chart for Occupation by churn\n",
        "grouped = df.groupby([' occupation', 'churn']).size().groupby(level=0).apply(lambda x: 100 * x / x.sum()).unstack('churn')\n",
        "\n",
        "grouped.plot(kind='bar', stacked=True, figsize=(10, 6))\n",
        "\n",
        "plt.title('Stacked Bar Chart of Occupation by Churn')\n",
        "plt.xlabel('Occupation')\n",
        "plt.ylabel('Count')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "prJJgM2fMuaO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove spaces from churn attribute\n",
        "df['churn'] = df['churn'].str.strip()"
      ],
      "metadata": {
        "id": "mrK1MrZNI_gk"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Simple Decision Tree"
      ],
      "metadata": {
        "id": "zMaV1N1CbrNv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Select features and target\n",
        "X = df.drop('churn', axis=1)\n",
        "y = df['churn']\n",
        "\n",
        "# Convert categorical variables to numeric using one-hot encoding\n",
        "X = pd.get_dummies(X)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "x2-A7LSRbtH-"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define classifier\n",
        "dt_classifier = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "# Fit\n",
        "dt_classifier.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "8HCGIHX0epFv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on the test data\n",
        "y_pred = dt_classifier.predict(X_test)\n",
        "\n",
        "# Calculate the accuracy of the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Accuracy: {accuracy}')"
      ],
      "metadata": {
        "id": "I_PaaX9WevIC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot tree\n",
        "from sklearn import tree\n",
        "\n",
        "# Very slow!\n",
        "\n",
        "plt.figure(figsize=(20,10))\n",
        "tree.plot_tree(dt_classifier, filled=True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "f8z7KIKdfmqF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Exercise - 5 minutes\n",
        "# Very large decision tree! Poor accuracy.\n",
        "# Why?"
      ],
      "metadata": {
        "id": "kwqg-z__gf9Q"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Depth\n",
        "dt_classifier.get_depth()"
      ],
      "metadata": {
        "id": "RalfpVYUgzMP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define classifier with smaller depth\n",
        "dt_classifier = DecisionTreeClassifier(random_state=42, max_depth=4)\n",
        "\n",
        "# Fit\n",
        "dt_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred = dt_classifier.predict(X_test)\n",
        "\n",
        "# Calculate the accuracy of the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Accuracy: {accuracy}')\n"
      ],
      "metadata": {
        "id": "WEHJYSasg2Hw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot tree\n",
        "plt.figure(figsize=(20,10))\n",
        "tree.plot_tree(dt_classifier, filled=True, feature_names=X.columns)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Z1iFJM8GhHHt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Exercise - 5 min\n",
        "# Can you find a setting for the max_depth hyperparameter\n",
        "# that produces an accuracy above 60%?\n"
      ],
      "metadata": {
        "id": "Gv30sdsFihR2"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Random Forest"
      ],
      "metadata": {
        "id": "Ms1_4NDRioOI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create and train the random forest classifier\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "clf = RandomForestClassifier(n_estimators=200, max_depth=20)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Evaluate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Random Forest Accuracy: {accuracy:.2f}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "Sdo3La6Dim5K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Exercise - 5 minutes\n",
        "# Can you find a setting of the n_estimator and max_depth hyperparameters\n",
        "# that produces an accuracy above 65%?"
      ],
      "metadata": {
        "id": "TaTf7yvfjV1Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### XGBoost"
      ],
      "metadata": {
        "id": "RdcBT1pAjch7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Convert [true false] to [1 0] because XGB requires this\n",
        "le = LabelEncoder()\n",
        "y_train = le.fit_transform(y_train)\n",
        "y_test = le.transform(y_test)\n",
        "\n",
        "xgb_model = XGBClassifier(n_estimators=100, learning_rate=0.1, max_depth=3)  # Adjust parameters as needed\n",
        "xgb_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = xgb_model.predict(X_test)\n",
        "\n",
        "# Evaluate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"XGBoost Accuracy: {accuracy:.2f}\")"
      ],
      "metadata": {
        "id": "9opn2nYHjeXy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Simple neural network"
      ],
      "metadata": {
        "id": "0rx0piqvud7l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.head()"
      ],
      "metadata": {
        "id": "U3mRNX0EK1Hu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Neural network\n",
        "\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "# Create the neural network model\n",
        "clf = MLPClassifier(hidden_layer_sizes=(64, 32), activation='relu', solver='adam', alpha=0.001, max_iter=100)\n",
        "\n",
        "# Train the model\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Evaluate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy:.2f}\")"
      ],
      "metadata": {
        "id": "iXUESvRouSDo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Neural network with several hidden layers"
      ],
      "metadata": {
        "id": "0Fzd-HaduscS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf = MLPClassifier(hidden_layer_sizes=(64, 32, 16, 8, 4), activation='relu', solver='adam', alpha=0.001, max_iter=100)\n",
        "\n",
        "# Train the model\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Evaluate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy:.2f}\")"
      ],
      "metadata": {
        "id": "-Rsa__bVuhW1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "abJ_dD_uyx8b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# But wait! We forgot to normalize all of the values between 0 and 1\n",
        "\n",
        "from sklearn.preprocessing import  MinMaxScaler\n",
        "\n",
        "# Create a MinMaxScaler object\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "\n",
        "# Fit the scaler on the training data (excluding the target variable)\n",
        "scaler.fit(X_train)\n",
        "\n",
        "# Transform the training features using the scaler\n",
        "X_train_scaled = scaler.transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "CaP-upqZxOja"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf = MLPClassifier(hidden_layer_sizes=(64, 32), activation='relu', solver='adam', alpha=0.001, max_iter=200)\n",
        "\n",
        "# Train the model\n",
        "clf.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = clf.predict(X_test_scaled)\n",
        "\n",
        "# Evaluate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy:.2f}\")"
      ],
      "metadata": {
        "id": "dd9--cjD0hMJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Natural Language Processing\n",
        "## IMDB Movies Sentiment Analysis\n",
        "\n",
        "Adapted from AI Publishing"
      ],
      "metadata": {
        "id": "w5vz3O_Xt8gD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "movie_dataset = pd.read_csv('imdb_reviews.csv', engine='python')"
      ],
      "metadata": {
        "id": "J-MOhoyhuofi"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "movie_dataset.head()"
      ],
      "metadata": {
        "id": "1MQY3nlU4PBp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "movie_dataset.shape"
      ],
      "metadata": {
        "id": "aXPW_0H64UZz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.rcParams[\"figure.figsize\"] = [8,10]\n",
        "\n",
        "movie_dataset.label.value_counts().plot(kind='pie', autopct=\"%1.0f%%\")"
      ],
      "metadata": {
        "id": "hV4j2kAV4W6D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = movie_dataset.text\n",
        "y = movie_dataset.label"
      ],
      "metadata": {
        "id": "WGvel8gB45nn"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def clean_text(doc):\n",
        "  # Keep letters only\n",
        "  document = re.sub('[^a-zA-Z]',' ',doc)\n",
        "  # Remove single characters\n",
        "  document = re.sub(r\"\\s+[a-zA-Z]\\s+\",' ',document)\n",
        "  # Remove multiple empty spaces\n",
        "  document = re.sub(r'\\s+',' ',document)\n",
        "\n",
        "  return document"
      ],
      "metadata": {
        "id": "GiAAu3Dj8EsP"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Clean reviews\n",
        "\n",
        "X_sentences = []\n",
        "reviews = list(X)\n",
        "for rev in reviews:\n",
        "  X_sentences.append(clean_text(rev))"
      ],
      "metadata": {
        "id": "J8tiW9v18ofC"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_sentences[0:4]"
      ],
      "metadata": {
        "id": "JWjlkJvw9OaI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Stop words and TFIDF\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# max_feature = 2000 => 2000 most common words\n",
        "# min_df = 5 => word must occur 5 times across all documents\n",
        "# max_df = 0.7 => word cannot occur in more than 70% of documents\n",
        "vectorizer = TfidfVectorizer(max_features=2000, min_df=5, max_df=0.7, stop_words=stopwords.words('english'))\n",
        "\n",
        "X = vectorizer.fit_transform(X_sentences).toarray()"
      ],
      "metadata": {
        "id": "aAjYyoi39bk1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X[0:4]"
      ],
      "metadata": {
        "id": "yNzupuY1-ptM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split into training and testing set\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "ZxFsVmwh-vkq"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "clf = RandomForestClassifier(n_estimators=250, random_state=42)\n",
        "# Takes 20 seconds\n",
        "clf.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "tEShifr3-87v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Performance\n",
        "\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, ConfusionMatrixDisplay\n",
        "\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "disp=ConfusionMatrixDisplay(confusion_matrix(y_test, y_pred))\n",
        "disp.plot()\n",
        "plt.show()\n",
        "\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(accuracy_score(y_test, y_pred))"
      ],
      "metadata": {
        "id": "yfd0IqWJ_PZs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5 minute exercise\n",
        "# Interpret the confusion matrix, the classification report, and the accuracy\n"
      ],
      "metadata": {
        "id": "nHgIJAHWDTAe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict an instance\n",
        "# 1 = positive sentiment, 0 = negative sentiment\n",
        "print(clf.predict(vectorizer.transform([\"The movie was excellent. I loved it.\"])))\n",
        "print(clf.predict(vectorizer.transform([\"The movie was terrible. I hated it.\"])))"
      ],
      "metadata": {
        "id": "SyPOnKK0DaF4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#5 minute exercis\n",
        "# Try other movie reviews. Are the results what you expected?"
      ],
      "metadata": {
        "id": "tgsU9e-TDv36"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convolutional Neural Network\n",
        "## Classifying objects in images\n",
        "\n",
        "Adapted from \"AI and Deep Learning\" by D'Ascoli\n"
      ],
      "metadata": {
        "id": "ZGgrwkQmE1Zt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "import matplotlib.pyplot as plot\n",
        "from keras.datasets import cifar10\n",
        "\n"
      ],
      "metadata": {
        "id": "HBNhe8iLE7yU"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data\n",
        "(X_train, Y_train), (X_test, Y_test) = cifar10.load_data()\n",
        "\n",
        "X_train.shape, Y_train.shape, X_test.shape, Y_test.shape"
      ],
      "metadata": {
        "id": "E6SCv6BHFS11"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot images\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "images = X_train[:20]\n",
        "\n",
        "fig, axs = plt.subplots(4, 5, figsize=(10, 5))\n",
        "\n",
        "for idx, ax in enumerate(axs.ravel()):\n",
        "    ax.imshow(images[idx], cmap='gray')\n",
        "    ax.set_title(f\"Label: {Y_train[idx]}\")\n",
        "    ax.axis('off')\n",
        "\n",
        "plt.show()\n",
        "\n",
        "# 0 airplane\n",
        "# 1 automobile (cars, not trucks or pickup trucks)\n",
        "# 2 bird\n",
        "# 3 cat\n",
        "# 4 deer\n",
        "# 5 dog\n",
        "# 6 frog\n",
        "# 7 horse\n",
        "# 8 ship\n",
        "# 9 truck (not pickup trucks)"
      ],
      "metadata": {
        "id": "q07UJm63S9jQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Scale values\n",
        "\n",
        "X_train, X_test = X_train/255.0, X_test/255.0"
      ],
      "metadata": {
        "id": "iSX9f6cfFlBP"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build network\n",
        "# First layer: 50 convolutional filters, 2x2\n",
        "\n",
        "CNN_model = models.Sequential()\n",
        "CNN_model.add(layers.Conv2D(50, (2, 2), activation='relu', input_shape=(32, 32, 3)))\n",
        "CNN_model.add(layers.MaxPooling2D((3,3)))\n",
        "CNN_model.add(layers.Flatten())\n",
        "CNN_model.add(layers.Dense(50, activation='relu'))\n",
        "CNN_model.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "6eRDVAS4FpeN"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = tf.optimizers.Adam(learning_rate = .005)\n",
        "CNN_model.compile(optimizer=optimizer, loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False), metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "dKOgsLRVONa2"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train model\n",
        "# take 10 minutes\n",
        "# Default batch size is 32\n",
        "history = CNN_model.fit(X_train, Y_train, epochs=5, validation_data=(X_test, Y_test))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SkHnbCcHOdwD",
        "outputId": "327f0fcb-ff13-4955-de29-5811661df09c"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1563/1563 [==============================] - 47s 30ms/step - loss: 1.6121 - accuracy: 0.4028 - val_loss: 1.4232 - val_accuracy: 0.4859\n",
            "Epoch 2/5\n",
            "1563/1563 [==============================] - 36s 23ms/step - loss: 1.3740 - accuracy: 0.5018 - val_loss: 1.3280 - val_accuracy: 0.5227\n",
            "Epoch 3/5\n",
            "1563/1563 [==============================] - 37s 23ms/step - loss: 1.3025 - accuracy: 0.5306 - val_loss: 1.2846 - val_accuracy: 0.5330\n",
            "Epoch 4/5\n",
            "1563/1563 [==============================] - 37s 23ms/step - loss: 1.2671 - accuracy: 0.5411 - val_loss: 1.2724 - val_accuracy: 0.5435\n",
            "Epoch 5/5\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 1.2309 - accuracy: 0.5535 - val_loss: 1.2563 - val_accuracy: 0.5425\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot performance\n",
        "import matplotlib.ticker as ticker\n",
        "\n",
        "plt.plot(history.history['accuracy'], label='accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(loc = 'upper left')\n",
        "plt.xticks(range(0, len(history.history['loss'])))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "DzsO1DK9P64d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print structure\n",
        "\n",
        "CNN_model.summary()\n"
      ],
      "metadata": {
        "id": "UhegajEQSrNS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The End"
      ],
      "metadata": {
        "id": "p1iLO7CpSvGz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}